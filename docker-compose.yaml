version: "3.9"

services:
  mongo:
    image: mongo:7
    container_name: quiz_mongo
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_DATABASE: quiz_app
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: ["CMD-SHELL", "mongosh --quiet --eval 'db.runCommand({ ping: 1 }).ok' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  ai_service:
    build:
      context: ./ai_service
      dockerfile: Dockerfile
    container_name: quiz_ai
    restart: unless-stopped
    depends_on:
      mongo:
        condition: service_healthy
    environment:
      MONGO_URI: mongodb://mongo:27017/
      MONGO_DB: quiz_app
      HOST: 0.0.0.0
      PORT: 5001
      ANALYSIS_WINDOW_DAYS: 7
      # ðŸ” mÃªme secret que Node (tu peux rÃ©utiliser celui prÃ©sent dans ai_service/.env)
      AI_SHARED_SECRET: ${AI_SHARED_SECRET:-mpi2023}
    ports:
      - "5001:5001"
    volumes:
      - ./hadoop/jars:/data:ro   # âŸµ rend word_counts.tsv visible pour Flask

  # â›”ï¸ Ne pas lancer par dÃ©faut (profils)
  mongo_seed:
    build:
      context: ./ai_service
      dockerfile: Dockerfile
    container_name: quiz_seed
    depends_on:
      mongo:
        condition: service_healthy
    environment:
      MONGO_URI: mongodb://mongo:27017/
      MONGO_DB: quiz_app
    command: ["python", "seed/seed_mongo.py"]
    restart: "no"
    profiles: ["seed"]

  node_backend:
    build:
      context: ./backend/nodejs/supa_quiz_server
    container_name: quiz_api
    restart: unless-stopped
    depends_on:
      ai_service:
        condition: service_started
      mongo:
        condition: service_healthy
    environment:
      # IA interne au rÃ©seau docker
      PY_AI_URL: http://ai_service:5001
      AI_SHARED_SECRET: ${AI_SHARED_SECRET:-mpi2023}
      # Mongo
      MONGO_URI: mongodb://mongo:27017/quiz_app
      MONGO_DB: quiz_app
      NODE_ENV: development
      PORT: 3001  # le conteneur Ã©coute en 3001 (Dockerfile), on publie 3000 dehors
    ports:
      - "3000:3001"  # ðŸ‘‰ http://localhost:3000 cÃ´tÃ© navigateur
    command: ["npm", "run", "start"]

  # â›”ï¸ Ne pas lancer par dÃ©faut (profils)
  ai_train:
    build:
      context: ./ai_service
      dockerfile: Dockerfile
    container_name: quiz_ai_train
    depends_on:
      mongo:
        condition: service_healthy
    environment:
      MONGO_URI: mongodb://mongo:27017/
      MONGO_DB: quiz_app
      MODEL_DIR: model
      DKT_EPOCHS: 6
    command: ["python", "train_dkt.py"]
    restart: "no"
    profiles: ["train"]

  go_admin:
    build:
      context: ./frontend/golang
      dockerfile: Dockerfile
    container_name: quiz_admin
    depends_on:
      mongo:
        condition: service_healthy
      node_backend:
        condition: service_started
    environment:
      # ðŸ‘‰ cible du backend applicatif Node (interne au rÃ©seau Docker)
      BACKEND_HOST: node_backend
      BACKEND_PORT: "3001"

      # ðŸ‘‰ Mongo pour lâ€™admin Go
      MONGO_URI: mongodb://mongo:27017/quiz_app
      MONGO_DB: quiz_app

      # (optionnel) si ton serveur Go lit un port via env, Ã©vite "PORT" pour ne pas confondre
      # ADMIN_PORT: "8080"
    ports:
      - "8080:8080"

  quiz-hadoop-master:
    image: liliasfaxi/spark-hadoop:hv-2.7.2
    container_name: quiz-hadoop-master
    hostname: quiz-hadoop-master
    command: >
      sh -lc "service ssh start &&
              /usr/local/hadoop/sbin/start-dfs.sh &&
              /usr/local/hadoop/sbin/start-yarn.sh &&
              tail -f /dev/null"
    volumes:
      - ./hadoop/jars:/opt/jars
      - ./hadoop/streaming:/opt/streaming
      - ./hadoop/config/core-site.xml:/usr/local/hadoop/etc/hadoop/core-site.xml:ro
      - ./hadoop/config/hdfs-site.xml:/usr/local/hadoop/etc/hadoop/hdfs-site.xml:ro
      - ./hadoop/config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml:ro
      - ./hadoop/config/mapred-site.xml:/usr/local/hadoop/etc/hadoop/mapred-site.xml:ro
    ports:
      - "9870:9870"   # HDFS NameNode UI
      - "8088:8088"   # YARN ResourceManager UI

  quiz-hadoop-dn1:
    image: liliasfaxi/spark-hadoop:hv-2.7.2
    container_name: quiz-hadoop-dn1
    hostname: quiz-hadoop-dn1
    command: >
      sh -lc "service ssh start &&
              /usr/local/hadoop/sbin/hadoop-daemon.sh start datanode &&
              /usr/local/hadoop/sbin/yarn-daemon.sh start nodemanager &&
              tail -f /dev/null"
    volumes:
      - dn1_data:/hadoop/dfs/data
      - ./hadoop/config/core-site.xml:/usr/local/hadoop/etc/hadoop/core-site.xml:ro
      - ./hadoop/config/hdfs-site.xml:/usr/local/hadoop/etc/hadoop/hdfs-site.xml:ro
      - ./hadoop/config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml:ro
      - ./hadoop/config/mapred-site.xml:/usr/local/hadoop/etc/hadoop/mapred-site.xml:ro

  quiz-hadoop-dn2:   # ðŸ‘ˆ bien alignÃ© avec dn1, PAS dedans
    image: liliasfaxi/spark-hadoop:hv-2.7.2
    container_name: quiz-hadoop-dn2
    hostname: quiz-hadoop-dn2
    command: >
      sh -lc "service ssh start &&
              /usr/local/hadoop/sbin/hadoop-daemon.sh start datanode &&
              /usr/local/hadoop/sbin/yarn-daemon.sh start nodemanager &&
              tail -f /dev/null"
    volumes:
      - dn2_data:/hadoop/dfs/data
      - ./hadoop/config/core-site.xml:/usr/local/hadoop/etc/hadoop/core-site.xml:ro
      - ./hadoop/config/hdfs-site.xml:/usr/local/hadoop/etc/hadoop/hdfs-site.xml:ro
      - ./hadoop/config/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml:ro
      - ./hadoop/config/mapred-site.xml:/usr/local/hadoop/etc/hadoop/mapred-site.xml:ro

volumes:
  mongo_data:
  nn_data:
  dn1_data:
  dn2_data:
